{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.datasets import fetch_20newsgroups, fetch_20newsgroups_vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'description', 'DESCR', 'target', 'filenames', 'target_names'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = fetch_20newsgroups()\n",
    "d.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['target_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<11314x130107 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1787565 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dv = fetch_20newsgroups_vectorized()\n",
    "type(dv)\n",
    "dv.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.30333333e+03   0.00000000e+00   3.33333333e-01] [ 501.35372299    0.81649658    1.24721913]\n",
      "[[-0.60502858 -1.22474487  1.33630621]\n",
      " [ 1.40951714  0.         -0.26726124]\n",
      " [-0.80448856  1.22474487 -1.06904497]]\n",
      "[[ 0.         -1.          1.33333333]\n",
      " [ 1.81981982  0.          0.        ]\n",
      " [-0.18018018  1.         -0.66666667]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import numpy as np\n",
    "\n",
    "a = np.array([ [ 1000., -1.,  2.],\n",
    "               [ 2010.,  0.,  0.],\n",
    "               [ 900.,  1., -1.]], dtype=np.float64)\n",
    "\n",
    "print(np.mean(a, axis=(0,)), np.std(a, axis=(0,)))\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "std_scaler.fit(a)\n",
    "s = std_scaler.transform(a)\n",
    "print(s)\n",
    "\n",
    "rob_scaler = RobustScaler()\n",
    "rob_scaler.fit(a)\n",
    "r = rob_scaler.transform(a)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "splits = train_test_split(dv.data, dv.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<8485x130107 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 1343713 stored elements in Compressed Sparse Row format>,\n",
       " <2829x130107 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 443852 stored elements in Compressed Sparse Row format>,\n",
       " array([16,  9, 13, ..., 17,  2,  7]),\n",
       " array([ 2,  3, 15, ...,  6, 15,  6])]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 130107)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dv.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = KFold(dv.data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.cross_validation.KFold(n=11314, n_folds=3, shuffle=False, random_state=None)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3772  3773  3774 ..., 11311 11312 11313] [   0    1    2 ..., 3769 3770 3771]\n",
      "[    0     1     2 ..., 11311 11312 11313] [3772 3773 3774 ..., 7540 7541 7542]\n",
      "[   0    1    2 ..., 7540 7541 7542] [ 7543  7544  7545 ..., 11311 11312 11313]\n"
     ]
    }
   ],
   "source": [
    "for tr, ts in f:\n",
    "    print(tr, ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cls = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit() missing 2 required positional arguments: 'X' and 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-f10ee050c558>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: fit() missing 2 required positional arguments: 'X' and 'y'"
     ]
    }
   ],
   "source": [
    "cls.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['able', 'are', 'betty', 'bitter', 'bought', 'but', 'butter', 'elba', 'ere', 'hello', 'how', 'more', 'saw', 'so', 'some', 'the', 'was', 'world', 'you']\n",
      "  (0, 9)\t1\n",
      "  (0, 17)\t1\n",
      "  (0, 10)\t2\n",
      "  (0, 1)\t1\n",
      "  (0, 18)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 16)\t1\n",
      "  (1, 8)\t1\n",
      "  (1, 12)\t1\n",
      "  (1, 7)\t1\n",
      "  (2, 16)\t1\n",
      "  (2, 2)\t2\n",
      "  (2, 4)\t2\n",
      "  (2, 14)\t2\n",
      "  (2, 6)\t3\n",
      "  (2, 5)\t1\n",
      "  (2, 15)\t1\n",
      "  (2, 3)\t1\n",
      "  (2, 13)\t1\n",
      "  (2, 11)\t1\n"
     ]
    }
   ],
   "source": [
    "docs = ['hello world how are you how', \n",
    "        'able was I ere I saw elba', \n",
    "        'betty bought some butter but the butter was bitter so betty bought some more butter']\n",
    "\n",
    "counts = CountVectorizer()\n",
    "term_freqs = counts.fit_transform(docs)\n",
    "print(counts.get_feature_names())\n",
    "print(term_freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['able', 'are', 'betty', 'bitter', 'bought', 'but', 'butter', 'elba', 'ere', 'hello', 'how', 'more', 'saw', 'so', 'some', 'the', 'was', 'world', 'you']\n",
      "  (0, 18)\t0.353553390593\n",
      "  (0, 1)\t0.353553390593\n",
      "  (0, 10)\t0.707106781187\n",
      "  (0, 17)\t0.353553390593\n",
      "  (0, 9)\t0.353553390593\n",
      "  (1, 7)\t0.467350981811\n",
      "  (1, 12)\t0.467350981811\n",
      "  (1, 8)\t0.467350981811\n",
      "  (1, 16)\t0.35543246785\n",
      "  (1, 0)\t0.467350981811\n",
      "  (2, 11)\t0.193970456486\n",
      "  (2, 13)\t0.193970456486\n",
      "  (2, 3)\t0.193970456486\n",
      "  (2, 15)\t0.193970456486\n",
      "  (2, 5)\t0.193970456486\n",
      "  (2, 6)\t0.581911369459\n",
      "  (2, 14)\t0.387940912973\n",
      "  (2, 4)\t0.387940912973\n",
      "  (2, 2)\t0.387940912973\n",
      "  (2, 16)\t0.147519531834\n",
      "[ 1.69314718  1.69314718  1.69314718  1.69314718  1.69314718  1.69314718\n",
      "  1.69314718  1.69314718  1.69314718  1.69314718  1.69314718  1.69314718\n",
      "  1.69314718  1.69314718  1.69314718  1.69314718  1.28768207  1.69314718\n",
      "  1.69314718]\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "tfidfs = tfidf.fit_transform(docs)\n",
    "print(tfidf.get_feature_names())\n",
    "print(tfidfs)\n",
    "print(tfidf.idf_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups_vectorized\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MaxAbsScaler\n",
    "from sklearn.cross_validation import train_test_split, KFold, StratifiedKFold, StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.metrics import average_precision_score, recall_score, precision_score, f1_score, cohen_kappa_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8485, 130107) (8485,)\n",
      "(2829, 130107) (2829,)\n"
     ]
    }
   ],
   "source": [
    "data = fetch_20newsgroups_vectorized()\n",
    "train_x, test_x, train_y, test_y = train_test_split(data.data, data.target)\n",
    "print(train_x.shape, train_y.shape)\n",
    "print(test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.24253138  5.16174651  5.22361676  5.21477815  5.10871487  5.24129397\n",
      "  5.17058512  5.25013258  5.28548701  5.2766484   5.30316422  5.25897119\n",
      "  5.22361676  5.25013258  5.24129397  5.29432561  4.82587944  4.98497437\n",
      "  4.10995227  3.33215485]\n"
     ]
    }
   ],
   "source": [
    "bin_counts = np.bincount(data.target)\n",
    "print(bin_counts / len(data.target) * 100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaler = MaxAbsScaler()\n",
    "scaler.fit(train_x)\n",
    "scaled_train_x = scaler.transform(train_x)\n",
    "scaled_test_x = scaler.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2829,)\n"
     ]
    }
   ],
   "source": [
    "cls = MultinomialNB()\n",
    "cls.fit(scaled_train_x, train_y)\n",
    "predicted_y = cls.predict(scaled_test_x)\n",
    "print(predicted_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.838812301166\n"
     ]
    }
   ],
   "source": [
    "acc_score = accuracy_score(test_y, predicted_y)\n",
    "print(\"Accuracy:\", acc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:\n",
      " [ 0.91666667  0.71052632  0.77380952  0.65        0.90441176  0.7721519\n",
      "  0.86363636  0.87012987  0.91891892  0.98726115  0.91975309  0.79190751\n",
      "  0.88235294  0.82        0.89240506  0.65957447  0.86754967  0.92352941\n",
      "  0.88990826  0.88888889]\n",
      "Recall:\n",
      " [ 0.80487805  0.81818182  0.45774648  0.82394366  0.75460123  0.87142857\n",
      "  0.67375887  0.87012987  0.95774648  0.90643275  0.98026316  0.93197279\n",
      "  0.78947368  0.9389313   0.90967742  0.95384615  0.95620438  0.97515528\n",
      "  0.81512605  0.42105263]\n",
      "F1-score:\n",
      " [ 0.85714286  0.76056338  0.57522124  0.72670807  0.82274247  0.81879195\n",
      "  0.75697211  0.87012987  0.93793103  0.94512195  0.94904459  0.85625\n",
      "  0.83333333  0.87544484  0.90095847  0.77987421  0.90972222  0.94864048\n",
      "  0.85087719  0.57142857]\n",
      "Support:\n",
      " [123 132 142 142 163 140 141 154 142 171 152 147 152 131 155 130 137 161\n",
      " 119  95]\n"
     ]
    }
   ],
   "source": [
    "precision, recall, fscore, support = precision_recall_fscore_support(test_y, predicted_y)\n",
    "print(\"Precision:\\n\", precision)\n",
    "print(\"Recall:\\n\", recall)\n",
    "print(\"F1-score:\\n\", fscore)\n",
    "print(\"Support:\\n\", support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate(dataset, classifier, scaler):\n",
    "    \n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "    \n",
    "    # Since class counts are slightly skewed, use StratifiedKFold instead of plain KFold.\n",
    "    # StratifiedKFold preserves the proportions of classes while sampling.\n",
    "    #\n",
    "    # What's the difference between StratifiedKFold, StratifiedKFold with shuffle=True, \n",
    "    # and StratifiedShuffleSplit? This question \n",
    "    # http://stackoverflow.com/questions/37635460/stratifiedkfold-vs-stratifiedshufflesplit-vs-stratifiedkfold-shuffle\n",
    "    # asks exactly that but doesn't provide an exact answer...\n",
    "    # http://scikit-learn.org/stable/modules/cross_validation.html probably answers it better, \n",
    "    # atleast the difference between Cross validation and shuffle splits, but needs to be understood\n",
    "    # in detail.\n",
    "    #\n",
    "    #folds = KFold(dataset.data.shape[0], n_folds = 10, shuffle = True)\n",
    "    folds = StratifiedKFold(dataset.target, n_folds = 10, shuffle = False)\n",
    "        \n",
    "    for training_rows, testing_rows in folds:\n",
    "        train_x = dataset.data[training_rows]\n",
    "        train_y = dataset.target[training_rows]\n",
    "\n",
    "        test_x = dataset.data[testing_rows]\n",
    "        test_y = dataset.target[testing_rows]\n",
    "\n",
    "        scaled_train_x = scaler.fit_transform(train_x)\n",
    "        scaled_test_x = scaler.transform(test_x)\n",
    "\n",
    "        cls.fit(scaled_train_x, train_y)\n",
    "        predicted_y = cls.predict(scaled_test_x)\n",
    "        #cls.fit(train_x, train_y)\n",
    "        #predicted_y = cls.predict(test_x)\n",
    "\n",
    "        acc_score = accuracy_score(test_y, predicted_y)\n",
    "        accuracies.append(acc_score)\n",
    "\n",
    "        # This is the average precision across all classes.\n",
    "        avg_prec = precision_score(test_y, predicted_y, average='macro')\n",
    "        precisions.append(avg_prec)\n",
    "\n",
    "        # This is the average recall across all classes.\n",
    "        avg_recall = recall_score(test_y, predicted_y, average='macro')\n",
    "        recalls.append(avg_recall)\n",
    "    \n",
    "    print(\"Accuracy:\", np.mean(accuracies))\n",
    "    print(\"Precision:\", np.mean(precisions))\n",
    "    print(\"Recall:\", np.mean(recalls))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.849587833524\n",
      "Precision: 0.858766856998\n",
      "Recalls: 0.842873622222\n"
     ]
    }
   ],
   "source": [
    "evaluate(data, MultinomialNB(fit_prior=False), MaxAbsScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.852327518887\n",
      "Precision: 0.861582207013\n",
      "Recalls: 0.845618342495\n"
     ]
    }
   ],
   "source": [
    "evaluate(data, MultinomialNB(fit_prior=True), MaxAbsScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.773277734168\n",
      "Precision: 0.774682391808\n",
      "Recalls: 0.773356405237\n"
     ]
    }
   ],
   "source": [
    "evaluate(data, MultinomialNB(), StandardScaler(with_mean=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.851326717706\n",
      "Precision: 0.86123036074\n",
      "Recalls: 0.844607339581\n"
     ]
    }
   ],
   "source": [
    "evaluate(data, RandomForestClassifier(), MaxAbsScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.850261687895\n",
      "Precision: 0.858972829991\n",
      "Recalls: 0.843628910402\n"
     ]
    }
   ],
   "source": [
    "evaluate(data, LogisticRegression(), MaxAbsScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.850818580052\n",
      "Precision: 0.859536632568\n",
      "Recalls: 0.844620412125\n"
     ]
    }
   ],
   "source": [
    "evaluate(data, GradientBoostingClassifier(), MaxAbsScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.852492931905\n",
      "Precision: 0.86253961696\n",
      "Recalls: 0.845750733135\n"
     ]
    }
   ],
   "source": [
    "evaluate(data, SGDClassifier(), MaxAbsScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.853105486186\n",
      "Precision: 0.861934433513\n",
      "Recalls: 0.846761403924\n"
     ]
    }
   ],
   "source": [
    "evaluate(data, XGBClassifier(), MaxAbsScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
